{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary torchgeometry torch pandas numpy==1.23.0 opencv-python wandb pillow imageio albumentations segmentation-models-pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, random_split, DataLoader, ConcatDataset\nimport albumentations as A\nimport torch.nn.functional as F\nfrom albumentations.pytorch.transforms import ToTensorV2\nimport torch.nn as nn\nfrom torchvision.transforms import ToTensor\nfrom PIL import Image\nimport os\nfrom torchsummary import summary\nimport torch\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:32.278861Z","iopub.execute_input":"2023-11-17T14:49:32.279237Z","iopub.status.idle":"2023-11-17T14:49:38.161515Z","shell.execute_reply.started":"2023-11-17T14:49:32.279203Z","shell.execute_reply":"2023-11-17T14:49:38.160616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:38.162630Z","iopub.execute_input":"2023-11-17T14:49:38.163015Z","iopub.status.idle":"2023-11-17T14:49:39.250064Z","shell.execute_reply.started":"2023-11-17T14:49:38.162990Z","shell.execute_reply":"2023-11-17T14:49:39.249009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.resize = resize\n        self.transform = transform\n        self.images = os.listdir(self.img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    def read_mask(self, mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.resize(image, self.resize)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n        # lower boundary RED color range values; Hue (0 - 10)\n        lower1 = np.array([0, 100, 20])\n        upper1 = np.array([10, 255, 255])\n        # upper boundary RED color range values; Hue (160 - 180)\n        lower2 = np.array([160,100,20])\n        upper2 = np.array([179,255,255])\n        lower_mask = cv2.inRange(image, lower1, upper1)\n        upper_mask = cv2.inRange(image, lower2, upper2)\n        \n        red_mask = lower_mask + upper_mask;\n        red_mask[red_mask != 0] = 1\n\n        # boundary GREEN color range values; Hue (36 - 70)\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n\n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = np.expand_dims(full_mask, axis=-1) \n        full_mask = full_mask.astype(np.uint8)\n        return full_mask\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        label_path = os.path.join(self.label_dir, self.images[idx])\n        image = cv2.imread(img_path) \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        label = self.read_mask(label_path)  \n        image = cv2.resize(image, self.resize)\n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image']\n            label = transformed['mask']\n        return image, label\n    def show_image(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        label_path = os.path.join(self.label_dir, self.images[idx])\n        image = plt.imread(img_path)\n        label = plt.imread(label_path)\n        fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n        axs[0].imshow(image)\n        axs[0].set_title('Image')\n        axs[1].imshow(label)\n        axs[1].set_title('Label')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:39.253289Z","iopub.execute_input":"2023-11-17T14:49:39.253645Z","iopub.status.idle":"2023-11-17T14:49:39.272985Z","shell.execute_reply.started":"2023-11-17T14:49:39.253614Z","shell.execute_reply":"2023-11-17T14:49:39.272124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = []\nTRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\nfor root, dirs, files in os.walk(TRAIN_DIR):\n    # iterate over 1000 images\n    for file in files:\n        # create path\n        path = os.path.join(root,file)\n        # add path to list\n        image_path.append(path)\nlen(image_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:39.274683Z","iopub.execute_input":"2023-11-17T14:49:39.275038Z","iopub.status.idle":"2023-11-17T14:49:39.643152Z","shell.execute_reply.started":"2023-11-17T14:49:39.275013Z","shell.execute_reply":"2023-11-17T14:49:39.642343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_path = []\nTRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\nfor root, dirs, files in os.walk(TRAIN_MASK_DIR):\n    #iterate over 1000 masks\n    for file in files:\n        # obtain the path\"\n        path = os.path.join(root,file)\n        # add path to the list\n        mask_path.append(path)\nlen(mask_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:39.644287Z","iopub.execute_input":"2023-11-17T14:49:39.644624Z","iopub.status.idle":"2023-11-17T14:49:39.993894Z","shell.execute_reply.started":"2023-11-17T14:49:39.644596Z","shell.execute_reply":"2023-11-17T14:49:39.992952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainsize = 384\nbatch_size = 12\n\ndataset = CustomImageDataset(img_dir= TRAIN_DIR,\n                             label_dir= TRAIN_MASK_DIR,\n                             resize= (trainsize,trainsize),\n                             transform = None)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:39.995221Z","iopub.execute_input":"2023-11-17T14:49:39.995631Z","iopub.status.idle":"2023-11-17T14:49:40.001883Z","shell.execute_reply.started":"2023-11-17T14:49:39.995596Z","shell.execute_reply":"2023-11-17T14:49:40.000779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_size = len(dataset)\ntrain_size = int(total_size * 0.8)\nvalid_size = total_size - train_size\n\n# Split the dataset\ntrain_dataset, val_dataset = random_split(dataset, [train_size, valid_size])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:40.003081Z","iopub.execute_input":"2023-11-17T14:49:40.003372Z","iopub.status.idle":"2023-11-17T14:49:40.032223Z","shell.execute_reply.started":"2023-11-17T14:49:40.003321Z","shell.execute_reply":"2023-11-17T14:49:40.031417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(CustomImageDataset):\n    def __init__(self, dataset, transform=None):\n        self.dataset = dataset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        image, label = self.dataset[index] \n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image']\n            label = transformed['mask']\n            label = label.permute(2,0,1)\n        return image, label\n\n    def __len__(self):\n        return len(self.dataset)\n\ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()]),\n    A.Cutout(p=0.2, max_h_size=35, max_w_size=35, fill_value=255),\n    A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n    A.RandomShadow(p=0.3),\n    A.ShiftScaleRotate(p=0.45, border_mode=cv2.BORDER_CONSTANT, rotate_limit=45, shift_limit=0.15, scale_limit=0.15),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\nval_transform = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\ntrain_dataset_not_aug = CustomDataset(train_dataset,\n                             transform = val_transform)\ntrain_dataset_aug = CustomDataset(train_dataset,\n                             transform = train_transform)\nval_dataset = CustomDataset(val_dataset,\n                             transform = val_transform)\n\ntrain_dataset_new = ConcatDataset([train_dataset_not_aug, train_dataset_aug])\n\ntrain_loader = DataLoader(train_dataset_new, batch_size= batch_size, shuffle= True)\nval_loader = DataLoader(val_dataset, batch_size= batch_size, shuffle= False)\nprint(len(train_dataset_new))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:40.033243Z","iopub.execute_input":"2023-11-17T14:49:40.033508Z","iopub.status.idle":"2023-11-17T14:49:40.050118Z","shell.execute_reply.started":"2023-11-17T14:49:40.033485Z","shell.execute_reply":"2023-11-17T14:49:40.049257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image,label = train_dataset_new[0]\nprint('Image: ', image.shape, 'Label: ', label.shape)\n\nlabel_array = label.permute(1, 2, 0).numpy()\nimage_array = image.permute(1, 2, 0).numpy()\n# Create a figure with 2 subplots (1 row, 2 columns)\nfig, axs = plt.subplots(1, 2, figsize=(10, 5))\n\naxs[0].imshow(image_array)\naxs[0].set_title('Image')\naxs[0].axis('off')  \n\naxs[1].imshow(label_array)\naxs[1].set_title('Label')\naxs[1].axis('off')  \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:40.051324Z","iopub.execute_input":"2023-11-17T14:49:40.051645Z","iopub.status.idle":"2023-11-17T14:49:40.557981Z","shell.execute_reply.started":"2023-11-17T14:49:40.051615Z","shell.execute_reply":"2023-11-17T14:49:40.556788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\nmodel = smp.UnetPlusPlus(encoder_name=\"resnet101\", encoder_weights=\"imagenet\", in_channels=3, classes=3)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:40.561894Z","iopub.execute_input":"2023-11-17T14:49:40.562220Z","iopub.status.idle":"2023-11-17T14:49:46.147415Z","shell.execute_reply.started":"2023-11-17T14:49:40.562192Z","shell.execute_reply":"2023-11-17T14:49:46.146444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nmodel = nn.DataParallel(model)\nmodel.to(device)\n\nsummary(model,(3, trainsize, trainsize))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:46.148728Z","iopub.execute_input":"2023-11-17T14:49:46.149089Z","iopub.status.idle":"2023-11-17T14:49:58.080055Z","shell.execute_reply.started":"2023-11-17T14:49:46.149056Z","shell.execute_reply":"2023-11-17T14:49:58.079054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 50\nlearning_rate = 0.0001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, \n                                    T_max=len(train_loader)*num_epochs,\n                                    eta_min=learning_rate/100)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:58.081503Z","iopub.execute_input":"2023-11-17T14:49:58.082290Z","iopub.status.idle":"2023-11-17T14:49:58.090323Z","shell.execute_reply.started":"2023-11-17T14:49:58.082250Z","shell.execute_reply":"2023-11-17T14:49:58.089259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path = '/kaggle/working/unet_model.pth'\n'''\ncheckpoint = torch.load(checkpoint_path)\nmodel.load_state_dict(checkpoint[\"model\"])\nmodel = nn.DataParallel(model)\nmodel.to(device)\noptimizer.load_state_dict(checkpoint['optimizer'])\n'''","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:58.091562Z","iopub.execute_input":"2023-11-17T14:49:58.091898Z","iopub.status.idle":"2023-11-17T14:49:58.104027Z","shell.execute_reply.started":"2023-11-17T14:49:58.091867Z","shell.execute_reply":"2023-11-17T14:49:58.103137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FocalLoss_Ori(nn.Module):\n\n    def __init__(self, num_class, alpha=None, gamma=2, ignore_index=None, reduction='mean'):\n        super(FocalLoss_Ori, self).__init__()\n        self.num_class = num_class\n        self.gamma = gamma\n        self.reduction = reduction\n        self.smooth = 1e-4\n        self.ignore_index = ignore_index\n        self.alpha = alpha\n        if alpha is None:\n            self.alpha = torch.ones(num_class, )\n        elif isinstance(alpha, (int, float)):\n            self.alpha = torch.as_tensor([alpha] * num_class)\n        elif isinstance(alpha, (list, np.ndarray)):\n            self.alpha = torch.as_tensor(alpha)\n        if self.alpha.shape[0] != num_class:\n            raise RuntimeError('the length not equal to number of class')\n\n    def forward(self, logit, target):\n        # assert isinstance(self.alpha,torch.Tensor)\\\n        N, C = logit.shape[:2]\n        alpha = self.alpha.to(logit.device)\n        prob = F.softmax(logit, dim=1)\n        if prob.dim() > 2:\n            # N,C,d1,d2 -> N,C,m (m=d1*d2*...)\n            prob = prob.view(N, C, -1)\n            prob = prob.transpose(1, 2).contiguous()  # [N,C,d1*d2..] -> [N,d1*d2..,C]\n            prob = prob.view(-1, prob.size(-1))  # [N,d1*d2..,C]-> [N*d1*d2..,C]\n        ori_shp = target.shape\n        target = target.view(-1, 1)  # [N,d1,d2,...]->[N*d1*d2*...,1]\n        valid_mask = None\n        if self.ignore_index is not None:\n            valid_mask = target != self.ignore_index\n            target = target * valid_mask\n\n        # ----------memory saving way--------\n        prob = prob.gather(1, target).view(-1) + self.smooth  # avoid nan\n        logpt = torch.log(prob)\n        # alpha_class = alpha.gather(0, target.view(-1))\n        alpha_class = alpha[target.squeeze().long()]\n        class_weight = -alpha_class * torch.pow(torch.sub(1.0, prob), self.gamma)\n        loss = class_weight * logpt\n        if valid_mask is not None:\n            loss = loss * valid_mask.squeeze()\n\n        if self.reduction == 'mean':\n            loss = loss.mean()\n            if valid_mask is not None:\n                loss = loss.sum() / valid_mask.sum()\n        elif self.reduction == 'none':\n            loss = loss.view(ori_shp)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:58.105566Z","iopub.execute_input":"2023-11-17T14:49:58.105861Z","iopub.status.idle":"2023-11-17T14:49:58.119831Z","shell.execute_reply.started":"2023-11-17T14:49:58.105836Z","shell.execute_reply":"2023-11-17T14:49:58.118953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nwandb.login(key = \"e4b97c6dcdac05b469bd619b1094adee24c24700\")","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:49:58.121048Z","iopub.execute_input":"2023-11-17T14:49:58.121731Z","iopub.status.idle":"2023-11-17T14:50:00.562086Z","shell.execute_reply.started":"2023-11-17T14:49:58.121697Z","shell.execute_reply":"2023-11-17T14:50:00.561182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(\n    project = 'Polyp_segmentation',\n    config = {\n        'learning_rate': 0.0001,\n        'architecture': 'unet++',\n        'dataset': 'Polyp',\n        'epoch': 50\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:50:00.563383Z","iopub.execute_input":"2023-11-17T14:50:00.564463Z","iopub.status.idle":"2023-11-17T14:50:31.280329Z","shell.execute_reply.started":"2023-11-17T14:50:00.564423Z","shell.execute_reply":"2023-11-17T14:50:31.279256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the number of training epochs\ncriterion = FocalLoss_Ori(num_class=3)\ntrain_loss_array = []\nval_loss_array = []\nbest_val_loss = 999\n# Training loop\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for batch_id ,(images, labels) in enumerate(train_loader, start = 1):\n        if epoch <= 1:\n            optimizer.param_groups[0][\"lr\"] = (epoch * batch_id) / (1.0 * num_epochs) * learning_rate\n        else:\n            scheduler.step()\n        images = images.to(device)\n        labels = labels.to(device)\n        # Forward pass\n        labels = labels.squeeze(dim=1).long()\n\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n\n        # Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        total_loss += loss.item()  # Accumulate the loss\n\n    train_loss_epoch = total_loss / len(train_loader)\n\n        \n# Perform validation\n    model.eval()\n    with torch.no_grad():\n        val_loss = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            labels = labels.squeeze(dim=1).long()\n\n            # Forward pass\n            outputs = model(images)\n            val_loss += criterion(outputs.float(),labels.long()).item()\n    val_loss_epoch = val_loss/len(val_loader)\n    # Print the loss of valid_dataset for this epoch\n    print(f\"Epoch [{epoch+1}/{num_epochs}], val_loss: {val_loss_epoch:.10f}\")\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        checkpoint = { \n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n        }\n        torch.save(checkpoint, checkpoint_path)\n        print('saved')\n    # Calculate average loss for the epoch\n    \n    wandb.log({'Val_loss': val_loss_epoch,\n               'Train_loss': train_loss_epoch,\n               'Scheduler': optimizer.param_groups[-1]['lr']\n              })\n    train_loss_array.append(train_loss_epoch)\n    val_loss_array.append(val_loss_epoch)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T14:50:31.281949Z","iopub.execute_input":"2023-11-17T14:50:31.282747Z","iopub.status.idle":"2023-11-17T16:39:34.127664Z","shell.execute_reply.started":"2023-11-17T14:50:31.282711Z","shell.execute_reply":"2023-11-17T16:39:34.124618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load(checkpoint_path)\nmodel.load_state_dict(checkpoint[\"model\"])\noptimizer.load_state_dict(checkpoint['optimizer'])","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:19.137770Z","iopub.execute_input":"2023-11-17T16:40:19.138208Z","iopub.status.idle":"2023-11-17T16:40:19.958100Z","shell.execute_reply.started":"2023-11-17T16:40:19.138175Z","shell.execute_reply":"2023-11-17T16:40:19.956966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams['figure.dpi'] = 90\nplt.rcParams['figure.figsize'] = (10, 5)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:23.396872Z","iopub.execute_input":"2023-11-17T16:40:23.397662Z","iopub.status.idle":"2023-11-17T16:40:23.404444Z","shell.execute_reply.started":"2023-11-17T16:40:23.397627Z","shell.execute_reply":"2023-11-17T16:40:23.403291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the training and validation loss\n\nplt.plot(train_loss_array, label='Training Loss')\nplt.plot(val_loss_array, label='Validation Loss')\n\n# Adding title and labels\nplt.title('Training and Validation Loss Per Epoch')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\n# Display the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:26.414943Z","iopub.execute_input":"2023-11-17T16:40:26.415353Z","iopub.status.idle":"2023-11-17T16:40:26.769662Z","shell.execute_reply.started":"2023-11-17T16:40:26.415319Z","shell.execute_reply":"2023-11-17T16:40:26.768428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = torch.load(checkpoint_path)\nmodel.load_state_dict(checkpoint['model'])\ndevice = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\noptimizer.load_state_dict(checkpoint['optimizer'])\nmodel.to(device)\nfor state in optimizer.state.values():\n    for k, v in state.items():\n        if isinstance(v, torch.Tensor):\n            state[k] = v.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:30.883210Z","iopub.execute_input":"2023-11-17T16:40:30.883596Z","iopub.status.idle":"2023-11-17T16:40:31.758659Z","shell.execute_reply.started":"2023-11-17T16:40:30.883566Z","shell.execute_reply":"2023-11-17T16:40:31.757478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"color_dict= {0: (0, 0, 0),\n             1: (255, 0, 0),\n             2: (0, 255, 0)}\ndef mask_to_rgb(mask, color_dict):\n    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n#     print(output.shape)\n    for k in color_dict.keys():\n        output[mask==k] = color_dict[k]\n\n    return np.uint8(output)    ","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:36.447220Z","iopub.execute_input":"2023-11-17T16:40:36.448149Z","iopub.status.idle":"2023-11-17T16:40:36.456255Z","shell.execute_reply.started":"2023-11-17T16:40:36.448109Z","shell.execute_reply":"2023-11-17T16:40:36.454679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir predicted_mask","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:39.671377Z","iopub.execute_input":"2023-11-17T16:40:39.672085Z","iopub.status.idle":"2023-11-17T16:40:40.745801Z","shell.execute_reply.started":"2023-11-17T16:40:39.672053Z","shell.execute_reply":"2023-11-17T16:40:40.742698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nfor i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n    ori_img = cv2.imread(img_path)\n    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n    ori_w = ori_img.shape[0]\n    ori_h = ori_img.shape[1]\n    img = cv2.resize(ori_img, (trainsize, trainsize))\n    transformed = val_transform(image=img)\n    input_img = transformed[\"image\"]\n    input_img = input_img.unsqueeze(0).to(device)\n    with torch.no_grad():\n        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n    mask = cv2.resize(output_mask, (ori_h, ori_w))\n    mask = np.argmax(mask, axis=2)\n    mask_rgb = mask_to_rgb(mask, color_dict)\n    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(\"predicted_mask/{}\".format(i), mask_rgb)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:40:44.807100Z","iopub.execute_input":"2023-11-17T16:40:44.807536Z","iopub.status.idle":"2023-11-17T16:41:30.289661Z","shell.execute_reply.started":"2023-11-17T16:40:44.807500Z","shell.execute_reply":"2023-11-17T16:41:30.288470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 225] = 255\n    pixels[pixels <= 225] = 0\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_mask' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T16:42:10.033444Z","iopub.execute_input":"2023-11-17T16:42:10.033846Z","iopub.status.idle":"2023-11-17T16:42:13.410069Z","shell.execute_reply.started":"2023-11-17T16:42:10.033816Z","shell.execute_reply":"2023-11-17T16:42:13.408719Z"},"trusted":true},"execution_count":null,"outputs":[]}]}